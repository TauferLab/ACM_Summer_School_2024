{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3edd4eb",
   "metadata": {},
   "source": [
    "# Tutorial: Using NSDF for End-to-End Analysis of Scientific Data\n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    "* Build a modular workflow integrating your application module with NSDF services for data visualization and analysis.\n",
    "* Load and store intermediate data from/to public storage options like Dataverse and from/to private storage such as Seal Storage.\n",
    "* Use the NSDF dashboard for data visualization and analysis. The analysis includes zooming into data for detailed analysis, cropping subregions, and saving them locally in a Python-compatible format.\n",
    "\n",
    "### **DISCLAIMER:** Please **DO NOT *Run All Cells*** because different paths can be executed leading to the same outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d090949",
   "metadata": {},
   "source": [
    "## Tutorial Overview\n",
    "\n",
    "The workflow in Figure 1 uses a chain of tools and services to showcase the NSDF capabilities for studying a geospatial dataset generated with [GEOtiled](https://github.com/TauferLab/GEOtiled/tree/main)[1] (a module of the [SOMOSPIE](https://github.com/TauferLab/SOMOSPIE) engine [2-3]). The workflow comprises four steps.\n",
    "\n",
    "**Step 1. Data Generation:** This initial step acquires data from the [United States Geological Survey (USGS)](https://www.usgs.gov/) and processes it with GEOtiled (Option A) or uploads the data from either a public or private storage (Option B).\n",
    "\n",
    "**Step 2. Conversion to IDX Format:** In this step, TIF files containing geospatial data from the first step are converted into IDX format using OpenVisus. This conversion process results in terrain parameter files that maintain the original accuracy but are more compact in size. These new, optimized files can be stored on either public or private storage solutions.\n",
    "\n",
    "**Step 3. Static Visualization:** The third stage uses the IDX files within OpenVisus for validating the data conversion and creating a static visualization using OpenVisus.\n",
    "\n",
    "**Step 4. Interactive Visualization and Analysis:** The last step launches a dashboard that allows users to work on large-scale data, extract and save subregions of the original dataset, and study and extract features. \n",
    "\n",
    "Throughout these steps, the workflow incorporates the use of public storage services (e.g., Dataverse, CyVerse) and private storage providers (e.g., Seal Storage, S3 AWS, IBM Cloud Object Storage). These services are connected to the conversion, visualization, and analysis steps, highlighting their crucial role in this tutorial's data processing and transformation steps.\n",
    "\n",
    "\n",
    "<div>\n",
    "<center><img src=\"files/docs/workflow-diagram.png\" width=\"800\"/>\n",
    "</div>\n",
    "<center><b>Figure 1:</b> Tutorial steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d70186",
   "metadata": {},
   "source": [
    "## -> Preparing your Environment \n",
    "\n",
    "***Note:** Run this cell to import all the necessary dependencies. Select the python kernel **\"NSDF-Tutorial\"**.* \n",
    "\n",
    "The following cell prepares the environment for processing and visualizing geospatial data by importing various crucial libraries for workflow execution. Please note that running this cell might take some time. Upon completion, a message will be displayed to notify you that the cell execution has finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf1f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geotiled as gt\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import multiprocessing\n",
    "import OpenVisus as ov\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# To silence a deprecation warning.\n",
    "gt.gdal.UseExceptions()\n",
    "\n",
    "# You have have successfully prepared your environment.\n",
    "print(\"You have successfully prepared your environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1412c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## -> Step 1. Data Generation\n",
    "\n",
    "Step 1 provides two options for users to obtain data: Option A allow the users to  downloading raw data from a public archive, such as elevation data from the USGS archive, and then processing it using the user's application, in this instance, the GEOtiled module from the [SOMOSPIE](https://github.com/TauferLab/SOMOSPIE) earth science application. Option B allows users to access data directly from existing public or private storage. In this instance we use existing data stored in [Dataverse](https://dataverse.harvard.edu/) without the need for initial downloading and processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a5066d-af62-4648-8919-e88b6e485f2c",
   "metadata": {},
   "source": [
    "\n",
    "###  Option A: Generating Data Using the SOMOSPIE Application Module\n",
    "\n",
    "We use the [SOMOSPIE](https://github.com/TauferLab/SOMOSPIE) application, specifically its GEOtiled module, to generate a high-resolution dataset of terrain parameters. This process involves using Digital Elevation Models (DEMs) from the USGS 3D Elevation Program as input. The GEOtiled module processes this data to produce two key terrain parameters: elevation, and hillshading, all at a 30 m resolution specifically for the state of Tennessee. The output consists of four TIFF format image files, each representing the calculated elevation, and hillshading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be19f48",
   "metadata": {},
   "source": [
    "The following cell sets initial paths, variable names and values used in the GEOtiled module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c295e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_list = \"./download_urls.txt\"  # Where the list of download links will be stored\n",
    "root_output_folder = \"./files/tif_files/\"  # root folder where geotiled will store data\n",
    "n_tiles = 4  # Number of tiles that are generated for parameter computation\n",
    "dem_tiles_dir_name = \"tiles\"  # Folder where downloaded DEM tiles will be saved\n",
    "param_tiles_dir_name = (\n",
    "    \"elevation_tiles\"  # Folder where computation tiles will be saved.\n",
    ")\n",
    "gcs_name = \"gcs.tif\"  # Name for the mosaicked DEM\n",
    "pcs_name = \"pcs.tif\"  # Name for the projected DEM\n",
    "shapefile = [\"./files/shape_files/STATEFP_47.shp\"]  # Shapefile for Visualization\n",
    "region_bounding_box = {\n",
    "    \"xmin\": -90.4,\n",
    "    \"ymin\": 34.8,\n",
    "    \"xmax\": -81.55,\n",
    "    \"ymax\": 36.8,\n",
    "}  # For `fetch_dem`. X=Longitude Y=Latitude. Determine bounding coordinates by looking at a map.\n",
    "\n",
    "print(\"You have successfully initialized the GEOtiled variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00276745",
   "metadata": {},
   "source": [
    "The following cell fetches the Digital Elevation Models (DEMs) from the USGS archive.\n",
    "\n",
    "***Note:** Because we are downloading data from USGS, the execution time of this cell depends on your Internet's speed.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548eff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching Data\n",
    "tiles_folder = os.path.join(root_output_folder, dem_tiles_dir_name)\n",
    "Path(root_output_folder).mkdir(parents=True, exist_ok=True)\n",
    "Path(tiles_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Setting up for parameter computation\n",
    "gcs = os.path.join(root_output_folder, gcs_name)\n",
    "pcs = os.path.join(root_output_folder, pcs_name)\n",
    "elevation_tiles = os.path.join(root_output_folder, param_tiles_dir_name)\n",
    "Path(elevation_tiles).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Computing Parameters\n",
    "hillshading_tiles = os.path.join(root_output_folder, \"hillshading_tiles\")\n",
    "Path(hillshading_tiles).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gt.fetch_dem(\n",
    "    bbox=region_bounding_box,\n",
    "    txtPath=download_list,\n",
    "    dataset=\"National Elevation Dataset (NED) 1 arc-second Current\",\n",
    ")\n",
    "gt.download_files(download_list, tiles_folder)\n",
    "\n",
    "print(\"You have successfully downloaded the DEMs from USGS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fbffae",
   "metadata": {},
   "source": [
    "The following cell deploys GEOtiled to process the downloaded DEMs, build a mosaic, reproject, and crop with buffers from preprocessing. If you would like to learn more about this workflow, please check the [GEOtiled module.](https://github.com/TauferLab/GEOtiled/tree/main)\n",
    "\n",
    "***Note:** This cell is merging all the DEMs and projecting them with the right coordinate system so it can take up to 5 mins.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a5202",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_list = glob.glob(tiles_folder + \"/*\")\n",
    "\n",
    "gt.build_mosaic(raster_list, gcs)\n",
    "\n",
    "shutil.rmtree(tiles_folder)\n",
    "os.remove(\"./merged.vrt\")\n",
    "\n",
    "gt.reproject(gcs, pcs, \"EPSG:9822\")\n",
    "\n",
    "os.remove(gcs)\n",
    "\n",
    "gt.crop_into_tiles(pcs, elevation_tiles, n_tiles)\n",
    "\n",
    "glob_of_tiles = glob.glob(elevation_tiles + \"/*.tif\")\n",
    "\n",
    "print(\"You have successfully processed the DEMs using GEOtiled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a45c22",
   "metadata": {},
   "source": [
    "The following cell takes the processed DEMs and calculates the other terrain parameter (hillshading). \n",
    "\n",
    "***Note:** This cell is compute-heavy because we are calculating the hillshading from the elevation. Therefore, it can take up to 10 mins.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=n_tiles)\n",
    "pool.map(gt.compute_geotiled, sorted(glob.glob(elevation_tiles + \"/*.tif\")))\n",
    "\n",
    "\n",
    "gt.build_mosaic_filtered(\n",
    "    sorted(glob.glob(hillshading_tiles + \"/*.tif\")),\n",
    "    os.path.join(root_output_folder, \"hillshading.tif\"),\n",
    ")\n",
    "\n",
    "shutil.rmtree(hillshading_tiles)\n",
    "shutil.rmtree(elevation_tiles)\n",
    "\n",
    "print(\"You have successfully computed all the terrain parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c83ed2",
   "metadata": {},
   "source": [
    "The following cell uses the GEOtiled library to visualize the two terrain parameters: elevation, and hillshading.\n",
    "\n",
    "***Note:** This cell can take up to 5 mins to visualize the data.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f780b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hill = os.path.join(root_output_folder, \"hillshading.tif\")\n",
    "pcs_array = gt.generate_img(\n",
    "    pcs,\n",
    "    downsample=5,\n",
    "    reproject_gcs=True,\n",
    "    shp_files=shapefile,\n",
    "    title=\"Elevation Data for TN @ 1 Arc-Second/30m Resolution\",\n",
    "    zunit=\"Meter\",\n",
    "    xyunit=\"Degree\",\n",
    "    ztype=\"Elevation\",\n",
    "    crop_shp=True,\n",
    ")\n",
    "hill_array = gt.generate_img(\n",
    "    hill,\n",
    "    downsample=5,\n",
    "    reproject_gcs=True,\n",
    "    shp_files=shapefile,\n",
    "    title=\"Hillshading Data for TN @ 1 Arc-Second/30m Resolution\",\n",
    "    zunit=\"Level\",\n",
    "    xyunit=\"Degree\",\n",
    "    ztype=\"Hillshading\",\n",
    "    crop_shp=True,\n",
    ")\n",
    "print(\"You have successfully visualized the 2 terrain parameters using GEOtiled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e53c05-d515-40c6-aa31-d5e2532a04b6",
   "metadata": {},
   "source": [
    "### -> Option B. Accessing Data from Dataverse Public Commons\n",
    "\n",
    "High-resolution data for elevation and hillshading at a 30m resolution for Tennessee might already exist in public storage repositories. If available, you can directly download this data to proceed to Step 2 without the need for initial data generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b782d",
   "metadata": {},
   "source": [
    "The following cell establishes a connection with a public storage service such as Dataverse and downloads previously generated TIFF files.\n",
    "\n",
    "***Note:** Because we are downloading data from Dataverse, the execution time of this cell depends on your Internet's speed.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5433cd70-319d-4e0c-b2aa-b9267fe9cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"files/tif_files\"):\n",
    "    os.mkdir(\"files/tif_files\")\n",
    "\n",
    "with open(\"./files/json/dataverse.json\", \"r\") as file:\n",
    "    urls = json.load(file)\n",
    "\n",
    "\n",
    "def get_data_from_dataverse(data):\n",
    "    file_url = data.get(\"url\")\n",
    "    name_file = data.get(\"name_file\")\n",
    "    resp = requests.get(file_url)\n",
    "    with open(name_file, \"wb\") as f:\n",
    "        f.write(resp.content)\n",
    "\n",
    "\n",
    "print(\"Your download is starting...\")\n",
    "\n",
    "pool = multiprocessing.Pool(processes=len(urls))\n",
    "pool.map(get_data_from_dataverse, urls)\n",
    "\n",
    "\n",
    "print(\"You have successfully downloaded the data from Dataverse.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb8a50",
   "metadata": {},
   "source": [
    "The following cell uses the GEOtiled library to verify the download step and visualize the two terrain parameters: elevation, and hillshading. \n",
    "***Note:** This cell can take up to 5 mins to visualize the data.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d0dda7-e5ba-4be3-b6f4-865ab31bf875",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile = [\"./files/shape_files/STATEFP_47.shp\"]  # Shapefile for Visualization\n",
    "hill = os.path.join(\"./files/tif_files/\", \"hillshading.tif\")\n",
    "pcs = os.path.join(\"./files/tif_files/\", \"elevation.tif\")\n",
    "\n",
    "pcs_array = gt.generate_img(\n",
    "    pcs,\n",
    "    downsample=5,\n",
    "    reproject_gcs=True,\n",
    "    shp_files=shapefile,\n",
    "    title=\"Elevation Data for TN @ 1 Arc-Second/30m Resolution\",\n",
    "    zunit=\"Meter\",\n",
    "    xyunit=\"Degree\",\n",
    "    ztype=\"Elevation\",\n",
    "    crop_shp=True,\n",
    ")\n",
    "hill_array = gt.generate_img(\n",
    "    hill,\n",
    "    downsample=5,\n",
    "    reproject_gcs=True,\n",
    "    shp_files=shapefile,\n",
    "    title=\"Hillshading Data for TN @ 1 Arc-Second/30m Resolution\",\n",
    "    zunit=\"Level\",\n",
    "    xyunit=\"Degree\",\n",
    "    ztype=\"Hillshading\",\n",
    "    crop_shp=True,\n",
    ")\n",
    "\n",
    "print(\"You have successfully visualized the data from Dataverse.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e1562",
   "metadata": {},
   "source": [
    "**_Important:_** The two images created by the GEOtiled module are high-resolution, large, and static. They do not allow users to manipulate the embedded information, including zooming into subregions, cropping them, and saving the cropped areas either locally or on other platforms for further analysis. Additionally, these images are provided in the TIFF format, which results in large file sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c079200",
   "metadata": {},
   "source": [
    "## -> Step 2: Converting to IDX Format\n",
    "\n",
    "After generating the data, it needs to be converted into the IDX format to be compatible with OpenVisus. This process involves creating a single IDX file that includes all the terrain parameters as distinct fields.\n",
    "\n",
    "***Note:** Completing one of the data generation options in Step 1 is a prerequisite for proceeding with this step.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803adb1f",
   "metadata": {},
   "source": [
    "The following cell extracts the geospatial metadata from one of the terrain parameters, in this case hillshading. This geospatial metadata provides reference to the coordinates and projection system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adfc770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate lat/lon min/max from tiff\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "hill = os.path.join(\"./files/tif_files/\", \"hillshading.tif\")\n",
    "\n",
    "dataset = gdal.Open(hill)\n",
    "band = dataset.GetRasterBand(1)\n",
    "\n",
    "geotransform = dataset.GetGeoTransform()\n",
    "spatial_ref = osr.SpatialReference(wkt=dataset.GetProjection())\n",
    "\n",
    "target_spatial_ref = osr.SpatialReference()\n",
    "target_spatial_ref.ImportFromEPSG(4326)\n",
    "\n",
    "coord_transform = osr.CoordinateTransformation(spatial_ref, target_spatial_ref)\n",
    "ulx, xres, _, uly, _, yres = geotransform\n",
    "lrx = ulx + (dataset.RasterXSize * xres)\n",
    "lry = uly + (dataset.RasterYSize * yres)\n",
    "top_left_geo = coord_transform.TransformPoint(ulx, uly)\n",
    "bottom_right_geo = coord_transform.TransformPoint(lrx, lry)\n",
    "\n",
    "lon_1, lat_1, _ = top_left_geo\n",
    "lon_2, lat_2, _ = bottom_right_geo\n",
    "lat_min = min(lat_1, lat_2)\n",
    "lat_max = max(lat_1, lat_2)\n",
    "lon_min = min(lon_1, lon_2)\n",
    "lon_max = max(lon_1, lon_2)\n",
    "\n",
    "print(f\"Longitude range: {lat_min} to {lat_max}\")\n",
    "print(f\"Latitude range: {lon_min} to {lon_max}\")\n",
    "\n",
    "print(\"You have successfully extract geospatial metadata from the TIFFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32dc120",
   "metadata": {},
   "source": [
    "The following cell takes the four terrain parameters and assign each to a different Field. `Fields` should be in this format: `[ov.Field(FIELD_NAME, DTYPE)]`. After the creation of the IDX, this one is compressed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885440a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"idx_data/Tennessee_terrain_parameters.idx\"\n",
    "all_fields = [ov.Field(\"elevation\", \"float32\"), ov.Field(\"hillshading\", \"uint8\")]\n",
    "input_data = [np.flipud(pcs_array).copy(), np.flipud(hill_array).copy()]\n",
    "height, width = input_data[0].shape\n",
    "db = ov.CreateIdx(\n",
    "    url=filename,\n",
    "    dims=[width, height],\n",
    "    fields=all_fields,\n",
    "    arco=\"4mb\",\n",
    "    physic_box=ov.BoxNd.fromString(f\"{lat_min} {lat_max} {lon_min} {lon_max}\"),\n",
    "    time=[0, 0, \"%00000d/\"],\n",
    ")\n",
    "i = 0\n",
    "for fld in db.getFields():\n",
    "    db.write(input_data[i], field=fld)\n",
    "    i += 1\n",
    "db.compressDataset([\"zip\"])\n",
    "\n",
    "print(\"You have successfully created the IDX file with the two terrain parmaters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e9c94",
   "metadata": {},
   "source": [
    "## -> Step 3: Static Visualization\n",
    "\n",
    "After the data has been generated, transformed into the correct format, and compressed, we proceed to validate the data by using Openvisus to visualize it. For this validation step, you can have data locally (Option A) or grab the IDX files previously stored from remote storage (Option B). For this specific example, we are using Seal Storage.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba3af5",
   "metadata": {},
   "source": [
    "### -> Option A: Loading the Dataset from Local Storage\n",
    "\n",
    "This option involves importing the dataset into the dashboard directly from local storage contained within the Docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4095c0f1",
   "metadata": {},
   "source": [
    "The following cell loads the dataset in IDX format from a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aae1cb-2fc0-4b83-b23a-7d8f691c014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"idx_data/Tennessee_terrain_parameters.idx\"\n",
    "db = ov.LoadDataset(filename)\n",
    "print(\"You have successfully loaded the IDX file with the two terrain parmaters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db980ecf",
   "metadata": {},
   "source": [
    "The followitng cell takes the loaded IDX files with Openvisus and statically visualizes it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c4f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_elevation = db.read(field=\"elevation\")\n",
    "read_hillshading = db.read(field=\"hillshading\")\n",
    "\n",
    "cmap_instance = plt.get_cmap(\"inferno\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "axs[0].set_xlim(lat_min, lat_max)\n",
    "axs[0].set_ylim(lon_min, lon_max)\n",
    "axs[0].set_title(\"Elevation - TN 30m Resolution\")\n",
    "axs[0].set_xlabel(\"Longitude (Degrees)\")\n",
    "axs[0].set_ylabel(\"Latitude (Degrees)\")\n",
    "elevation_fig = axs[0].imshow(\n",
    "    read_elevation,\n",
    "    cmap=cmap_instance,\n",
    "    origin=\"lower\",\n",
    "    vmin=30,\n",
    "    vmax=1999,\n",
    "    extent=(lat_min, lat_max, lon_min, lon_max),\n",
    ")\n",
    "\n",
    "cbar = fig.colorbar(\n",
    "    elevation_fig,\n",
    "    fraction=0.046 * read_elevation.shape[0] / read_elevation.shape[1],\n",
    "    pad=0.04,\n",
    ")\n",
    "cbar_ticks = np.linspace(30, 1999, 8)\n",
    "cbar.set_ticks(cbar_ticks)\n",
    "cbar.set_label(\"Elevation (Meters)\")\n",
    "\n",
    "axs[1].set_xlim(lat_min, lat_max)\n",
    "axs[1].set_ylim(lon_min, lon_max)\n",
    "axs[1].set_title(\"Hillshading - TN 30m Resolution\")\n",
    "axs[1].set_xlabel(\"Longitude (Degrees)\")\n",
    "axs[1].set_ylabel(\"Latitude (Degrees)\")\n",
    "hillshading_fig = axs[1].imshow(\n",
    "    read_hillshading,\n",
    "    cmap=cmap_instance,\n",
    "    origin=\"lower\",\n",
    "    vmin=0,\n",
    "    vmax=255,\n",
    "    extent=(lat_min, lat_max, lon_min, lon_max),\n",
    ")\n",
    "\n",
    "cbar = fig.colorbar(\n",
    "    hillshading_fig,\n",
    "    fraction=0.046 * read_hillshading.shape[0] / read_hillshading.shape[1],\n",
    "    pad=0.04,\n",
    ")\n",
    "cbar_ticks = np.linspace(0, 255, 8)\n",
    "cbar.set_ticks(cbar_ticks)\n",
    "cbar.set_label(\"Hillshading (Levels)\")\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "print(\"You have successfully visualized the IDX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28cc77-c18d-476c-87a5-210dbb62bf55",
   "metadata": {},
   "source": [
    "**_Important:_** These images are the visualization of the IDX compressed dataset for the four terrain parameters. They serve as validation for the conversion from TIFF to IDX, ensuring the reduction in the size of the data without losing the accuracy. However, this visualization does not allow users to manipulate the embedded information, including zooming into subregions, cropping them, and saving the cropped areas either locally or on other platforms for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d18e6e",
   "metadata": {},
   "source": [
    "### Option B: Loading the Dataset from Seal Storage\n",
    "\n",
    "For this option, the IDX dataset is uploaded into the dashboard from a private archive that has been previously generated and stored in Seal Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5975cb46",
   "metadata": {},
   "source": [
    "The following cell establishes a connection with a private storage service such as Seal Storage and downloads previously generated IDX files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db099e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Tennessee_terrain_parameters.idx\"\n",
    "HOME_DIR = \"s3://utah/nsdf/somospie/\"  # DONOT change this line\n",
    "data_dir = \"terrain_tennessee/\"\n",
    "upload_dir = HOME_DIR + data_dir\n",
    "s3_path = upload_dir.split(\"://\")[1]\n",
    "s3_path += filename\n",
    "remote_dir = (\n",
    "    \"https://maritime.sealstorage.io/api/v0/s3/\"\n",
    "    + s3_path\n",
    "    + \"?access_key=any&secret_key=any&endpoint_url=https://maritime.sealstorage.io/api/v0/s3&cached=arco\"\n",
    ")\n",
    "\n",
    "db = ov.LoadDataset(remote_dir)\n",
    "\n",
    "print(\"You have successfully downloaded the IDX files from Seal Storage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cc75cb",
   "metadata": {},
   "source": [
    "The followitng cell takes the loaded IDX files with Openvisus and statically visualizes it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a340c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_elevation = db.read(field=\"elevation\")\n",
    "read_hillshading = db.read(field=\"hillshading\")\n",
    "read_aspect = db.read(field=\"aspect\")\n",
    "read_slope = db.read(field=\"slope\")\n",
    "\n",
    "cmap_instance = plt.get_cmap(\"inferno\")\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(10, 8))\n",
    "axs[0].set_xlim(lat_min, lat_max)\n",
    "axs[0].set_ylim(lon_min, lon_max)\n",
    "axs[0].set_title(\"Elevation - TN 30m Resolution\")\n",
    "axs[0].set_xlabel(\"Longitude (Degrees)\")\n",
    "axs[0].set_ylabel(\"Latitude (Degrees)\")\n",
    "elevation_fig = axs[0].imshow(\n",
    "    read_elevation,\n",
    "    cmap=cmap_instance,\n",
    "    origin=\"lower\",\n",
    "    vmin=30,\n",
    "    vmax=1999,\n",
    "    extent=(lat_min, lat_max, lon_min, lon_max),\n",
    ")\n",
    "\n",
    "cbar = fig.colorbar(\n",
    "    elevation_fig,\n",
    "    fraction=0.046 * read_elevation.shape[0] / read_elevation.shape[1],\n",
    "    pad=0.04,\n",
    ")\n",
    "cbar_ticks = np.linspace(30, 1999, 8)\n",
    "cbar.set_ticks(cbar_ticks)\n",
    "cbar.set_label(\"Elevation (Meters)\")\n",
    "\n",
    "axs[1].set_xlim(lat_min, lat_max)\n",
    "axs[1].set_ylim(lon_min, lon_max)\n",
    "axs[1].set_title(\"Hillshading - TN 30m Resolution\")\n",
    "axs[1].set_xlabel(\"Longitude (Degrees)\")\n",
    "axs[1].set_ylabel(\"Latitude (Degrees)\")\n",
    "hillshading_fig = axs[1].imshow(\n",
    "    read_hillshading,\n",
    "    cmap=cmap_instance,\n",
    "    origin=\"lower\",\n",
    "    vmin=0,\n",
    "    vmax=255,\n",
    "    extent=(lat_min, lat_max, lon_min, lon_max),\n",
    ")\n",
    "\n",
    "cbar = fig.colorbar(\n",
    "    hillshading_fig,\n",
    "    fraction=0.046 * read_hillshading.shape[0] / read_hillshading.shape[1],\n",
    "    pad=0.04,\n",
    ")\n",
    "cbar_ticks = np.linspace(0, 255, 8)\n",
    "cbar.set_ticks(cbar_ticks)\n",
    "cbar.set_label(\"Hillshading (Levels)\")\n",
    "\n",
    "axs[2].set_xlim(lat_min, lat_max)\n",
    "axs[3].set_ylim(lon_min, lon_max)\n",
    "axs[2].set_title(\"Aspect - TN 30m Resolution\")\n",
    "axs[2].set_xlabel(\"Longitude (Degrees)\")\n",
    "axs[2].set_ylabel(\"Latitude (Degrees)\")\n",
    "aspect_fig = axs[2].imshow(\n",
    "    read_aspect,\n",
    "    cmap=cmap_instance,\n",
    "    vmin=0,\n",
    "    origin=\"lower\",\n",
    "    vmax=360,\n",
    "    extent=(lat_min, lat_max, lon_min, lon_max),\n",
    ")\n",
    "\n",
    "\n",
    "cbar = fig.colorbar(\n",
    "    aspect_fig, fraction=0.046 * read_aspect.shape[0] / read_aspect.shape[1], pad=0.04\n",
    ")\n",
    "cbar_ticks = np.linspace(0, 360, 8)\n",
    "cbar.set_ticks(cbar_ticks)\n",
    "cbar.set_label(\"Aspect (Degrees)\")\n",
    "\n",
    "axs[3].set_xlim(lat_min, lat_max)\n",
    "axs[3].set_ylim(lon_min, lon_max)\n",
    "axs[3].set_title(\"Slope - TN 30m Resolution\")\n",
    "axs[3].set_xlabel(\"Longitude (Degrees)\")\n",
    "axs[3].set_ylabel(\"Latitude (Degrees)\")\n",
    "slope_fig = axs[3].imshow(\n",
    "    read_slope,\n",
    "    cmap=cmap_instance,\n",
    "    vmin=0,\n",
    "    origin=\"lower\",\n",
    "    vmax=65.9,\n",
    "    extent=(lat_min, lat_max, lon_min, lon_max),\n",
    ")\n",
    "\n",
    "\n",
    "cbar = fig.colorbar(\n",
    "    slope_fig, fraction=0.046 * read_slope.shape[0] / read_slope.shape[1], pad=0.04\n",
    ")\n",
    "cbar_ticks = np.linspace(0, 65.9, 8)\n",
    "cbar.set_ticks(cbar_ticks)\n",
    "cbar.set_label(\"Slope (Degrees)\")\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"You have successfully visualized the IDX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e176d51b",
   "metadata": {},
   "source": [
    "## -> Step 4: Interactive Visualization and Analysis of Geospatial Data Using the NSDF Dashboard \n",
    "\n",
    "After validating the correct conversion from TIFF to IDX and visualizing statically the data. We create a dashboard that enables scientists to interact, visualize, and analyze geospatial data. You can zoom into data for detailed analysis, cropping subregions, and saving them locally in a Python-compatible format. For this step, you can have data locally (Option A) or grab the IDX files previously stored from remote storage (Option B). \n",
    "\n",
    "We present two geographical regions. The first region is for the state of Tennessee for consistency of the tutorial. However, we want to go beyond and show the power of interacting with a large geospatial dataset that may not fit in your local computer, for example, the Contiguous United States at 30 m resolution. \n",
    "\n",
    "***Note: When running multiple regions make sure to stop and run one dashboard launching cell at the time***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3dca37-1b7d-4ca7-82b0-aa1d35708045",
   "metadata": {},
   "source": [
    "This cell configures the Port and Address settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b3656-dc02-4849-9354-a9abf3f50c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "PORT = \"8989\"  # Dont change this since this is the forwarded port.\n",
    "ADDRESS = \"0.0.0.0\"  # Local to the server; 0.0.0.0 or 127.0.0.1\n",
    "\n",
    "print(\"You have successfully set the port for the dashboard.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ebaa8d-d041-4d9c-8418-39abbb3d6a7a",
   "metadata": {},
   "source": [
    "### -> Geographical Region: Tennessee\n",
    "For the first data scenario, you can interact with geospatial data in IDX format from Tennessee. You can load from local storage (Option A) or from remote storage (Option B).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc4909",
   "metadata": {},
   "source": [
    "#### -> Option A. Load dataset from a local storage\n",
    "\n",
    "This cell uploads data from local storage to input in the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"idx_data/Tennessee_terrain_parameters.idx\"\n",
    "\n",
    "print(\"You have successfully loaded local IDX data for Tennessee.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb8e5a-dd0c-4eaa-8b44-6733a2d8527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Stop this cell before running another visualization dashboard\n",
    "!python -m panel serve openvisuspy/src/openvisuspy/dashboards --log-file \"files/log.log\" --dev --allow-websocket-origin='*' --address=\"{ADDRESS}\" --port \"{PORT}\" --args \"{URL}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2a5798-4d05-49fd-8d65-60be07100e8c",
   "metadata": {},
   "source": [
    "##### Visit http://localhost:8989 to explore the dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01cc449",
   "metadata": {},
   "source": [
    "#### Option B. Load dataset from Seal Storage\n",
    "\n",
    "This cell uploads data from a Seal Storage as input in the dashboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57edc5-a3c5-420f-8989-a07996ca3148",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://maritime.sealstorage.io/api/v0/s3/utah/nsdf/somospie/tennessee_30m_terrain/Tennessee_terrain_parameters.idx?access_key=any&secret_key=any&endpoint_url=https://maritime.sealstorage.io/api/v0/s3&cached=arco\"\n",
    "print(\"You have successfully loaded the IDX Tennessee data from remote storage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b37ea-c79c-414c-bae0-99b101901b29",
   "metadata": {},
   "source": [
    "This cell executes the dashboard, enabling us to zoom into specific subregions of the state of Tennessee and examine the terrain parameter patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596942a-9307-439d-bf27-e75c77a91ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Stop this cell before running another visualization dashboard\n",
    "!python -m panel serve openvisuspy/src/openvisuspy/dashboards --log-file \"files/log.log\" --dev --allow-websocket-origin='*' --address=\"{ADDRESS}\" --port \"{PORT}\" --args \"{URL}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e7138-bbbe-4368-8b2f-d6989830f7c0",
   "metadata": {},
   "source": [
    "##### Visit http://localhost:8989 to explore the dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782e001a-e36d-473d-849a-630cb09567cf",
   "metadata": {},
   "source": [
    "### -> Geographical Region: Contiguous United States\n",
    "\n",
    "For the second data scenario, you can interact with geospatial data in IDX format from the Contiguous United States without storing this large dataset locally. The dashboard directly streams the data from remote storage, in this case, Seal Storage. You can interact with the data through the NSDF dashboard, zoom in, and select specific subregions of interest to download on your local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb9eef-bec5-4d28-bd3b-eee781b99b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://maritime.sealstorage.io/api/v0/s3/utah/nsdf/somospie/conus_30m_terrain/CONUS_30m_Terrain_Parameters.idx?access_key=any&secret_key=any&endpoint_url=https://maritime.sealstorage.io/api/v0/s3&cached=arco\"\n",
    "\n",
    "print(\"You have successfully loaded the IDX CONUS data from remote storage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44ec5b-2cee-4a13-959e-8fe26b58627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Stop this cell before running another visualization dashboard\n",
    "!python -m panel serve openvisuspy/src/openvisuspy/dashboards --log-file \"files/log.log\" --dev --allow-websocket-origin='*' --address=\"{ADDRESS}\" --port \"{PORT}\" --args \"{URL}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c7bc7a-c7bf-4c7f-90f1-1ad2799fe541",
   "metadata": {},
   "source": [
    "##### Visit http://localhost:8989 to explore the dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b1d06c",
   "metadata": {},
   "source": [
    "## Learn More About SOMOSPIE and GEOtiled\n",
    "[1] Roa, C., Olaya, P., Llamas, R., Vargas, R., Taufer, M. GEOtiled: A Scalable Workflow for Generating Large Datasets of High-Resolution Terrain Parameters. Proceedings of the 32nd International Symposium on High-Performance Parallel and Distributed Computing (2023). [link](https://dl.acm.org/doi/abs/10.1145/3588195.3595941)\n",
    "\n",
    "[2] Olaya, P., Luettgau, J., Roa, C., Llamas, R., Vargas, R., Wen, S., Chung, I., Seelam, S., Park, Y., Lofstead, J., and Taufer, M. Enabling Scalability in the Cloud for Scientific Workflows: An Earth Science Use Case. IEEE International Conference on Cloud Computing (2023). [link](https://research.ibm.com/publications/enabling-scalability-in-the-cloud-for-scientific-workflows-an-earth-science-use-case)\n",
    "\n",
    "[3] Rorabaugh, D., Guevara, M., Llamas, R., Kitson, J., Vargas, R., and Taufer, M. SOMOSPIE: A modular SOil MOisture SPatial Inference Engine based on data-driven decisions. In Proceedings of the 2019 15th International Conference on eScience (eScience) (2019). [link](https://ieeexplore.ieee.org/document/9041768)\n",
    "\n",
    "## Learn More About Openvisus\n",
    "[4] V. Pascucci and R. J. Frank, \"Global Static Indexing for Real-Time Exploration of Very Large Regular Grids,\" SC '01: Proceedings of the 2001 ACM/IEEE Conference on Supercomputing, Denver, CO, USA, 2001, pp. 45-45, [link](http://doi.org/10.1145/582034.582036)\n",
    "\n",
    "[5] Pascucci, Valerio, et al. \"The ViSUS visualization framework.\" High Performance Visualization. Chapman and Hall/CRC, 2012. 439-452. [link](https://www.taylorfrancis.com/chapters/edit/10.1201/b12985-32/visus-visualization-frame[…]a-gyulassy-cameron-christensen-sujin-philip-sidharth-kumar)\n",
    "\n",
    "[6] Brian Summa, Giorgio Scorzelli, Ming Jiang, Peer-Timo Bremer, and Valerio Pascucci. 2011. Interactive editing of massive imagery made simple: Turning Atlanta into Atlantis. ACM Trans. Graph. 30, 2, Article 7 (April 2011), 13 pages. [link](https://doi.org/10.1145/1944846.1944847)\n",
    "\n",
    "## Contact Us\n",
    "\n",
    "Please, contact us through the [NSDF team](https://nationalsciencedatafabric.org/contributors.html)'s email info@nationalsciencedatafabric.org or directly to the [SOMOSPIE](https://globalcomputing.group/somospie/) PIs, Dr. Michela Taufer mtaufer@utk.edu and Rodrigo Vargas.\n",
    "\n",
    "## Acknowledgment\n",
    "The authors of this tutorial would like to express their gratitude to:\n",
    "\n",
    "* NSF through the awards 2138811, 2103845, 2334945, and 2331152.\n",
    "* The Dataverse team [link](https://dataverse.org/about)\n",
    "* The Seal Storage team [link](https://www.sealstorage.io/home/#team)\n",
    "* Vargas Lab led by Dr. Rodrigo Vargas [link](https://www.udel.edu/academics/colleges/canr/departments/plant-and-soil-sciences/faculty-staff/rodrigo-vargas/)\n",
    "\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"files/docs/Logos.png\" width=\"450\"/>\n",
    "</div>\n",
    "<center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562aeb5-b022-424e-b572-3d241e2243cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

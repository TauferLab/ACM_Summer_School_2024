{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# HDF5 streamable version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# import openvisus\n",
    "if os.path.isdir(r\"C:\\projects\\OpenVisus\\build\\RelWithDebInfo\"):\n",
    "\tsys.path.append(r\"C:\\projects\\OpenVisus\\build\\RelWithDebInfo\")\n",
    "\n",
    "import OpenVisus as ov\n",
    "os.environ[\"VISUS_DISABLE_WRITE_LOCK\"]=\"1\"\n",
    "\n",
    "from create_streamable import Streamable\n",
    "from xarray_backend import OpenVisusBackendEntrypoint\n",
    "\n",
    "# NEEDED\n",
    "#   OpenVisus need credentials that will extract from s3 config file\n",
    "#   you need to have a `~/.aws/config` file with the profile\n",
    "assert(os.path.isfile(os.path.expanduser(\"~/.aws/config\")))\n",
    "\n",
    "# *** CHANGE AS NEEDED ****\n",
    "#   NOTE:  always better to have a directory which contains all h5 and OpenVisus file, for this reason I am using `dirname` for templates below\n",
    "\n",
    "# original file\n",
    "h5_filename         = './reconstructed_data.nxs'\n",
    "expression          ='/shanks-3731-a/data/reconstructed_data'\n",
    "group,fieldname     = expression.rsplit(\"/\",maxsplit=1) # xarray needs to read one level-up (i.e. at group level)\n",
    "\n",
    "# create streamable local version, where each 3d field will be an OpenVisus dataset\n",
    "local_url           = f\"./streamable/hdf5/reconstructed_data/visus.nxs\"\n",
    "\n",
    "# upload to S3\n",
    "profile             = \"sealstorage\"\n",
    "endpoint_url        = f\"https://maritime.sealstorage.io/api/v0/s3\"\n",
    "\n",
    "# this is where to get the file from the network \n",
    "# -   NOTE: OpenVisus server does not support serving files such as HDF5 directly, we need a solution on apache\n",
    "remote_url          = f\"https://maritime.sealstorage.io/api/v0/s3/utah/streamable/hdf5/reconstructed_data/visus.nxs?profile=\" + profile\n",
    "\n",
    "# {name} is the internal HDF5 expression to reach the data\n",
    "idx_urls={\n",
    "\n",
    "\t# alias to a dic item that will be used for the `public`\n",
    "\t\"default\":         \"remote\",\n",
    "\n",
    "\t# this is needed to generate interal local dtaset\n",
    "\t\"local\":            os.path.splitext(local_url)[0]+\"/{name}/visus.idx\",\n",
    "\n",
    "\t# network s3 storage\n",
    "\t\"remote\":           os.path.splitext(remote_url)[0]+\"/{name}/visus.idx?cached=arco&profile=\" + profile, \n",
    "\n",
    "\t# **TODO** this is missing the {name} in case of multiple fielcs inside the H5\n",
    "\t\"remote-atlantis\": \"https://atlantis.sci.utah.edu/mod_visus?action=readdataset&dataset=reconstructed_data&cached=arco?cached=arco\" \n",
    "}\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(idx_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from original HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(h5_filename, group=group)\n",
    "field=ds[fieldname]\n",
    "data=field[...].values\n",
    "print(\"Got data\",\"type\",type(data),\"shape\",data.shape,\"dtype\",data.dtype,\"min\",np.min(data),\"max\",np.max(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use H5glance too\n",
    "- Execute `!{sys.executable} -m pip install --quiet h5glance` if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5glance import H5Glance\n",
    "H5Glance(h5_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create streamable version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arco  = \"2mb\"\n",
    "compression = \"zip\"\n",
    "Streamable.Create(h5_filename, local_url, arco=arco, compression=compression, idx_urls=idx_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Streamable.Print(local_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read  local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(local_url, group=group, engine=OpenVisusBackendEntrypoint, prefer=\"local\")\n",
    "field=ds[fieldname]\n",
    "timestep,res=0,27\n",
    "data=field[timestep,...,res].values\n",
    "print(\"Got data\",\"type\",type(data),\"shape\",data.shape,\"dtype\",data.dtype,\"min\",np.min(data),\"max\",np.max(data))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(data[100,...]) \n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload all folder (H5 files and IDX data) to S3\n",
    "\n",
    "It is important to have an unique folder to simplify the upload\n",
    "- **TODO** OpenVisus server would need a modification to the `visus.config` file , so it's not easy to make the upload automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install --quiet awscli-plugin-endpoint\n",
    "!aws s3 sync --no-progress --endpoint-url {endpoint_url} --profile {profile} --size-only {os.path.dirname(local_url)}/ s3:/{os.path.dirname(remote_url)[len(endpoint_url):]}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Read from S3\n",
    "\n",
    "- the streamable file already contains `cached=arco` so it should automatically cache data\n",
    "- check your `~/visus/` directory for cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly opening the stream using f3fs is causing some problems with `xr.open_dataset` so I am saving the file locally first\n",
    "temp_local_url=Streamable.SaveRemoteToLocal(remote_url, profile=profile, endpoint_url=endpoint_url)\n",
    "\n",
    "ds=xr.open_dataset(temp_local_url, group=group, engine=OpenVisusBackendEntrypoint, prefer=\"remote\")\n",
    "field=ds[fieldname]\n",
    "timestep,res=0,27\n",
    "data=field[timestep,...,res].values\n",
    "print(\"Got data\",\"type\",type(data),\"shape\",data.shape,\"dtype\",data.dtype,\"min\",np.min(data),\"max\",np.max(data))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(data[100,...]) \n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from atlantis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenVisus server does not support serving any file such as streamable HDF5, so I need another place\n",
    "ds=xr.open_dataset(local_url, group=group, engine=OpenVisusBackendEntrypoint, prefer=\"remote-atlantis\")\n",
    "field=ds[fieldname]\n",
    "timestep,res=0,27\n",
    "data=field[timestep,...,res].values\n",
    "print(\"Got data\",\"type\",type(data),\"shape\",data.shape,\"dtype\",data.dtype,\"min\",np.min(data),\"max\",np.max(data))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(data[100,...]) \n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- support of direct HDF5  (i.e. using `h5py` with `HDF5_PLUGIN_PATH`)\n",
    "- support of direct NEXUS (i.e. ?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
